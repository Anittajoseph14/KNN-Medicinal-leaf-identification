{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNJfxFbtsWJ3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the uploaded zip file and extraction location\n",
        "zip_file = '/content/drive/MyDrive/archive.zip' # Update with the correct path to your zip file\n",
        "output_dir = '/content/extracted_files'  # Specify the directory to extract to\n",
        "\n"
      ],
      "metadata": {
        "id": "Gt01gJgDswG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "De9yiNcxs1ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile # Import the zipfile module\n",
        "\n"
      ],
      "metadata": {
        "id": "uFyvGMp7tE9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_dir)\n",
        "\n",
        "print(f\"Files extracted to {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3bHOZIPtJ-t",
        "outputId": "c4084899-2625-4a19-e298-405aeed9878c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to /content/extracted_files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the dataset folder containing images\n",
        "images_dir = os.path.join('/content/extracted_files', '/content/extracted_files/Segmented Medicinal Leaf Images')\n",
        "\n",
        "# Create train, validation, and test directories\n",
        "train_dir = '/content/dataset/train/'\n",
        "validation_dir = '/content/dataset/validation/'\n",
        "test_dir = '/content/dataset/test/'\n",
        "\n",
        "# Create subdirectories for each class\n",
        "class_names = os.listdir(images_dir)\n",
        "for class_name in class_names:\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(validation_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
        "\n",
        "# Split the data into train, test, and validation sets (80% train, 10% validation, 10% test)\n",
        "for class_name in class_names:\n",
        "    class_path = os.path.join(images_dir, class_name)\n",
        "    all_images = os.listdir(class_path)\n",
        "\n",
        "    # Split into train/validation/test\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    train_images, temp_images = train_test_split(all_images, test_size=0.2, random_state=42)\n",
        "    validation_images, test_images = train_test_split(temp_images, test_size=0.5, random_state=42)\n",
        "\n",
        "    # Move the images to respective folders\n",
        "    import shutil\n",
        "\n",
        "    for img in train_images:\n",
        "        shutil.copy(os.path.join(class_path, img), os.path.join(train_dir, class_name, img))\n",
        "    for img in validation_images:\n",
        "        shutil.copy(os.path.join(class_path, img), os.path.join(validation_dir, class_name, img))\n",
        "    for img in test_images:\n",
        "        shutil.copy(os.path.join(class_path, img), os.path.join(test_dir, class_name, img))\n",
        "\n",
        "print(\"Dataset organized into train, validation, and test sets!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QCQEcpYkaBI",
        "outputId": "238ed0f7-0ae3-4452-8a36-65af6942b4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset organized into train, validation, and test sets!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set dataset directory and image dimensions\n",
        "dataset_dir = '/content/extracted_files/Segmented Medicinal Leaf Images'  # Update this with your dataset path\n",
        "img_height, img_width = 128, 128  # Resize images to speed up processing\n",
        "\n",
        "# Initialize data and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Load images and extract features (flattened image pixels)\n",
        "for class_name in os.listdir(dataset_dir):\n",
        "    class_path = os.path.join(dataset_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        for img_file in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_file)\n",
        "            try:\n",
        "                # Load and preprocess the image\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.resize(img, (img_height, img_width))  # Resize image to 128x128\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "                data.append(img.flatten())  # Flatten the image into a 1D array\n",
        "                labels.append(class_name)  # Add the class label\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img_path}: {e}\")\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(f\"Loaded {len(data)} images.\")\n",
        "\n",
        "# Encode class labels into numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data for better performance\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)  # Fit and transform on the training data\n",
        "X_test = scaler.transform(X_test)  # Transform the testing data based on the training set\n",
        "\n",
        "print(\"Data preprocessing complete.\")\n",
        "\n",
        "# Define the KNN model\n",
        "k = 5  # Number of neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Train the KNN model\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "print(\"KNN model training complete.\")\n",
        "\n",
        "# Evaluate the KNN model\n",
        "def evaluate_model(knn_model, X_test, y_test, label_encoder):\n",
        "    \"\"\"\n",
        "    Evaluate the KNN model and print precision, recall, F1 score, and classification report.\n",
        "    \"\"\"\n",
        "    # Predict using the test data\n",
        "    y_pred_encoded = knn_model.predict(X_test)\n",
        "    y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
        "    y_test_decoded = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "    # Classification report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test_decoded, y_pred))\n",
        "\n",
        "    # Calculate and print precision, recall, and F1 score\n",
        "    precision = precision_score(y_test_decoded, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test_decoded, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test_decoded, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Example usage\n",
        "evaluate_model(knn, X_test, y_test, label_encoder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PIV0d5gnn2M",
        "outputId": "49b7b8f1-e036-4def-9d09-7d21531b847b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1835 images.\n",
            "Data preprocessing complete.\n",
            "KNN model training complete.\n",
            "Classification Report:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "            Arive-Dantu       0.50      0.79      0.61        19\n",
            "                 Basale       0.74      0.64      0.68        22\n",
            "                  Betel       0.88      0.50      0.64        14\n",
            "          Crape_Jasmine       0.67      0.55      0.60        11\n",
            "                  Curry       0.12      0.12      0.12         8\n",
            "              Drumstick       0.71      0.71      0.71        17\n",
            "              Fenugreek       0.89      0.80      0.84        10\n",
            "                  Guava       0.74      1.00      0.85        14\n",
            "               Hibiscus       0.91      0.77      0.83        13\n",
            "           Indian_Beech       0.83      0.56      0.67         9\n",
            "         Indian_Mustard       0.67      0.18      0.29        11\n",
            "              Jackfruit       1.00      0.80      0.89        15\n",
            "Jamaica_Cherry-Gasagase       0.50      0.86      0.63         7\n",
            "                  Jamun       1.00      0.78      0.88         9\n",
            "                Jasmine       0.53      0.77      0.62        13\n",
            "                Karanda       0.55      1.00      0.71        17\n",
            "                  Lemon       0.33      0.50      0.40        10\n",
            "                  Mango       0.89      0.67      0.76        12\n",
            "           Mexican_Mint       0.60      0.60      0.60         5\n",
            "                   Mint       0.78      0.75      0.77        24\n",
            "                   Neem       1.00      0.17      0.29        12\n",
            "               Oleander       0.69      0.90      0.78        10\n",
            "               Parijata       1.00      0.40      0.57         5\n",
            "                 Peepal       0.92      1.00      0.96        12\n",
            "            Pomegranate       0.71      0.67      0.69        18\n",
            "                  Rasna       0.88      1.00      0.93        14\n",
            "             Rose_apple       1.00      0.80      0.89        10\n",
            "           Roxburgh_fig       1.00      0.44      0.62         9\n",
            "             Sandalwood       0.50      0.45      0.48        11\n",
            "                  Tulsi       0.30      0.50      0.38         6\n",
            "\n",
            "               accuracy                           0.68       367\n",
            "              macro avg       0.73      0.66      0.66       367\n",
            "           weighted avg       0.74      0.68      0.68       367\n",
            "\n",
            "Precision: 0.74\n",
            "Recall: 0.68\n",
            "F1 Score: 0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to your images\n",
        "dataset_dir = '/content/extracted_files/Segmented Medicinal Leaf Images'\n",
        "\n",
        "# Initialize data and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Load images and extract features\n",
        "for class_name in os.listdir(dataset_dir):\n",
        "    class_path = os.path.join(dataset_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        for img_file in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_file)\n",
        "            try:\n",
        "                # Load and preprocess the image\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.resize(img, (img_height, img_width))\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                data.append(img.flatten())  # Flatten the image into a 1D array\n",
        "\n",
        "                # Label as \"Medicinal\" or \"Non-Medicinal\"\n",
        "                if 'medicinal' in class_name.lower():  # Modify this condition if needed\n",
        "                    labels.append('Medicinal')\n",
        "                else:\n",
        "                    labels.append('Non-Medicinal')\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img_path}: {e}\")\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "id": "jxr9SDWxpKxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode class labels (Medicinal and Non-Medicinal) into numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n"
      ],
      "metadata": {
        "id": "-JRUVS5VpSwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data for better performance\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define and train the KNN model\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "print(\"KNN model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkTPtwTLpWuI",
        "outputId": "b9bfd93c-143d-4448-857f-993e5dba74c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_leaf(image_path, knn_model, label_encoder, scaler, img_height=128, img_width=128):\n",
        "    \"\"\"\n",
        "    Predict if the given leaf image is medicinal or non-medicinal.\n",
        "\n",
        "    Parameters:\n",
        "    - image_path: Path to the user's leaf image\n",
        "    - knn_model: Trained KNN model\n",
        "    - label_encoder: Label encoder for class labels\n",
        "    - scaler: Scaler used for standardizing the data\n",
        "    - img_height, img_width: Resize dimensions for the image\n",
        "\n",
        "    Returns:\n",
        "    - Predicted class (Medicinal/Non-Medicinal)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load and preprocess the input image\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.resize(img, (img_height, img_width))  # Resize image\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "        img_flattened = img.flatten()  # Flatten the image\n",
        "\n",
        "        # Standardize the image data using the scaler\n",
        "        img_standardized = scaler.transform([img_flattened])\n",
        "\n",
        "        # Predict using the trained KNN model\n",
        "        pred_label_encoded = knn_model.predict(img_standardized)\n",
        "        pred_label = label_encoder.inverse_transform(pred_label_encoded)[0]\n",
        "\n",
        "        # Return the predicted label\n",
        "        return pred_label\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "1iFwFI2fpawd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the user's leaf image\n",
        "user_image_path = '/content/sample_data/amarnthus.jpg'  # Replace with the actual image path\n",
        "\n",
        "# Predict if the given leaf is medicinal or non-medicinal\n",
        "predicted_class = predict_leaf(user_image_path, knn, label_encoder, scaler)\n",
        "\n",
        "# Display the result\n",
        "if predicted_class:\n",
        "    print(f\"The given leaf is predicted to be: {predicted_class}\")\n",
        "else:\n",
        "    print(\"Prediction failed. Please check the image or model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9rzXvDtpgiU",
        "outputId": "aeadde96-a3d4-4060-ea1e-9c72ce67cded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given leaf is predicted to be: Non-Medicinal\n"
          ]
        }
      ]
    }
  ]
}